{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deepadarshni/SentimentAnalysis-of-UserReviews-with-EmojiAnalysis/blob/main/Sentiment_Analysis_of_User_reviews_with_emoji_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VJSeLl5EIlk",
        "outputId": "6a6e09a8-7129-415f-9e40-a6dc3b46392c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/358.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/358.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.8.0\n",
            "Collecting emoji==1.7.0\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=5c36ee3da245bfc2b18513d1fdca893d8eaef1323f50b0efae21851a48bd344b\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "  Attempting uninstall: emoji\n",
            "    Found existing installation: emoji 2.8.0\n",
            "    Uninstalling emoji-2.8.0:\n",
            "      Successfully uninstalled emoji-2.8.0\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji\n",
        "!pip install emoji==1.7.0\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from scipy.stats import pearsonr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymDrQBP5FnSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c453ba85-bd3a-4fd4-d941-5765bad1b232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     text     label\n",
            "0                    Amazing features 😍 🤩  positive\n",
            "1                 I love this product ! 😊  positive\n",
            "2                       worst quality 😞 😞  negative\n",
            "3        Not satisfied with the product 👎  negative\n",
            "4         I am happy with the feature 🤩 🤑  positive\n",
            "5               It's an average product 🤔   neutral\n",
            "6   Terrible quality,regret buying it 👎 👎  negative\n",
            "7                     could be better 🤔 😐   neutral\n",
            "8       I am satisfied with my purchase 😊  positive\n",
            "9                Not recommended to buy 🥲  negative\n",
            "10                Absolutely love it! 😊 💯  positive\n",
            "11      Very disappointing experience 🥲 🥲  negative\n",
            "12                  Worst purchase ever 😞  negative\n",
            "13                  It's okay,not great 🤔   neutral\n",
            "14         Excellent customer service 😍 😍  positive\n",
            "15       The design is sleek and modern 🤩  positive\n",
            "16         Very user-friendly product 👏 👏  positive\n",
            "17  Disappointed with the performance 🥲 🥲  negative\n",
            "18          Exceeded my expectation 🤩 💯 💯  positive\n",
            "19              The software is buggy 💩 💩  negative\n",
            "20        could use some improvements 🤔 🤔   neutral\n",
            "21              Well-packaged,no damage 😊  positive\n",
            "22            The material feel cheap 🚀 🚀  positive\n",
            "23                 The color is vibrant 🤩  positive\n",
            "24                  Not user-friendly 😞 😞  negative\n",
            "25         The product arrived damage 🥲 🥲  negative\n",
            "26                Not worth the price 👎 👎  negative\n",
            "27                        Low quality 👎 😞  negative\n",
            "28                   Difficult to use 😞 😞  negative\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('Customer Reviews1.csv')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLquYc2rFnWF"
      },
      "outputs": [],
      "source": [
        "# Analyze sentiment of emojis during preprocessing\n",
        "def preprocess_and_analyze_sentiment(text):\n",
        "    text = emoji.demojize(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Analyze sentiment of emojis\n",
        "    emojis = [char for char in text if char in emoji.demojize(text)]\n",
        "    # Map emoji names to sentiments\n",
        "    emoji_sentiment_mapping = {\n",
        "        ':smiling_face_with_heart-eyes:': 'positive', ':thumbs_up:': 'positive', ':clap:': 'positive', ':star_struck:': 'positive',\n",
        "        ':disappointed:': 'negative', ':thumbs_down:': 'negative', ':sob:': 'negative', ':angry:': 'negative',':pensive_face:':'negative',\n",
        "        ':smile:': 'positive', ':thinking_face:': 'neutral', ':money_mouth_face:': 'positive',\n",
        "        ':face_with_rolling_eyes:': 'negative', ':rocket:': 'positive', ':poop:': 'negative',\n",
        "        ':shopping_bags:': 'positive', ':100:': 'positive',':crying_face:':'negative'\n",
        "    }\n",
        "    sentiment = [emoji_sentiment_mapping.get(char, 'neutral') for char in emojis]\n",
        "\n",
        "    return text, sentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ch95BwxFnkn",
        "outputId": "9031cd34-2b99-4426-ff9b-ff4da3905672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 text  \\\n",
            "0   amazing features :smiling_face_with_heart-eyes...   \n",
            "1   i love this product ! :smiling_face_with_smili...   \n",
            "2   worst quality :disappointed_face: :disappointe...   \n",
            "3        not satisfied with the product :thumbs_down:   \n",
            "4   i am happy with the feature :star-struck: :mon...   \n",
            "5             it's an average product :thinking_face:   \n",
            "6   terrible quality,regret buying it :thumbs_down...   \n",
            "7      could be better :thinking_face: :neutral_face:   \n",
            "8   i am satisfied with my purchase :smiling_face_...   \n",
            "9     not recommended to buy :smiling_face_with_tear:   \n",
            "10  absolutely love it! :smiling_face_with_smiling...   \n",
            "11  very disappointing experience :smiling_face_wi...   \n",
            "12            worst purchase ever :disappointed_face:   \n",
            "13                it's okay,not great :thinking_face:   \n",
            "14  excellent customer service :smiling_face_with_...   \n",
            "15       the design is sleek and modern :star-struck:   \n",
            "16  very user-friendly product :clapping_hands: :c...   \n",
            "17  disappointed with the performance :smiling_fac...   \n",
            "18  exceeded my expectation :star-struck: :hundred...   \n",
            "19  the software is buggy :pile_of_poo: :pile_of_poo:   \n",
            "20  could use some improvements :thinking_face: :t...   \n",
            "21  well-packaged,no damage :smiling_face_with_smi...   \n",
            "22          the material feel cheap :rocket: :rocket:   \n",
            "23                 the color is vibrant :star-struck:   \n",
            "24  not user-friendly :disappointed_face: :disappo...   \n",
            "25  the product arrived damage :smiling_face_with_...   \n",
            "26    not worth the price :thumbs_down: :thumbs_down:   \n",
            "27      low quality :thumbs_down: :disappointed_face:   \n",
            "28  difficult to use :disappointed_face: :disappoi...   \n",
            "\n",
            "                                      emoji_sentiment  \n",
            "0   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "1   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "2   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "3   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "4   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "5   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "6   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "7   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "8   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "9   [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "10  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "11  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "12  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "13  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "14  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "15  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "16  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "17  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "18  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "19  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "20  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "21  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "22  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "23  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "24  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "25  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "26  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "27  [neutral, neutral, neutral, neutral, neutral, ...  \n",
            "28  [neutral, neutral, neutral, neutral, neutral, ...  \n"
          ]
        }
      ],
      "source": [
        "# Apply preprocessing and sentiment analysis\n",
        "df[['text', 'emoji_sentiment']] = df['text'].apply(preprocess_and_analyze_sentiment).apply(pd.Series)\n",
        "print(df[['text', 'emoji_sentiment']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGYkF7h1Fnsi"
      },
      "outputs": [],
      "source": [
        "# Feature extraction using TF-IDF and Skip N-gram\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['text']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf_Z_fXaHAcb"
      },
      "outputs": [],
      "source": [
        "# Merge TF-IDF features with sentiment of emojis\n",
        "X_combined = np.concatenate([X_tfidf, np.array(df['emoji_sentiment'].apply(lambda x: 1 if 'positive' in x else (-1 if 'negative' in x else 0))).reshape(-1, 1)], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN1XyKLCHBU-",
        "outputId": "3f5c79b8-6d93-417a-e1f1-a5847a8bbadd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 0 0 2 1 0 1 2 0 2 0 0 1 2 2 2 0 2 0 1 2 2 2 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'].values)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hddnQpXkHBeY",
        "outputId": "6fe0a292-c158-4e41-bf7f-e8b5d6ae6e2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(stats.ConstantInputWarning(msg))\n"
          ]
        }
      ],
      "source": [
        "# Pearson correlation coefficient for feature selection\n",
        "correlations = [pearsonr(X_combined[:, i], y)[0] for i in range(X_combined.shape[1])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqvTh3lLFnv-"
      },
      "outputs": [],
      "source": [
        "# Select features based on correlation threshold (you can adjust this threshold)\n",
        "selected_features = [i for i, corr in enumerate(correlations) if abs(corr) > 0.1]\n",
        "X_selected = X_combined[:, selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK9HQY7KJ2wd"
      },
      "outputs": [],
      "source": [
        "# Tokenize and pad sequences for RNN-LSTM\n",
        "max_words_text = 1000\n",
        "max_len_text = 20\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words_text, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
        "tokenizer.fit_on_texts(df['text'].values)\n",
        "X_text = tokenizer.texts_to_sequences(df['text'].values)\n",
        "X_text = pad_sequences(X_text, maxlen=max_len_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5ORrWuUJ2yj"
      },
      "outputs": [],
      "source": [
        "# Build the RNN-LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words_text, output_dim=50, input_length=max_len_text))\n",
        "model.add(LSTM(units=100, activation='tanh'))\n",
        "model.add(Dense(units=10, activation='relu'))\n",
        "model.add(Dense(units=3, activation='softmax'))  # Output layer for three classes (positive, negative, neutral)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAj2HrgyJ21m"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2quApkjZJ24H"
      },
      "outputs": [],
      "source": [
        "# Train-test split for RNN-LSTM\n",
        "X_train_text, X_test_text, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)\n",
        "X_train_selected, X_test_selected, _, _ = train_test_split(X_selected, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGukDEWAKPN_",
        "outputId": "57dc7f08-9f8c-41f0-bed2-5456f20805a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.0990 - accuracy: 0.2222 - val_loss: 1.0965 - val_accuracy: 0.4000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 1.0949 - accuracy: 0.3889 - val_loss: 1.0928 - val_accuracy: 0.4000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 1.0898 - accuracy: 0.3889 - val_loss: 1.0898 - val_accuracy: 0.4000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.0850 - accuracy: 0.5556 - val_loss: 1.0866 - val_accuracy: 0.4000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1.0790 - accuracy: 0.5556 - val_loss: 1.0834 - val_accuracy: 0.4000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1.0725 - accuracy: 0.5556 - val_loss: 1.0791 - val_accuracy: 0.4000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1.0648 - accuracy: 0.5556 - val_loss: 1.0744 - val_accuracy: 0.4000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 1.0563 - accuracy: 0.5556 - val_loss: 1.0691 - val_accuracy: 0.4000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 1.0469 - accuracy: 0.7222 - val_loss: 1.0629 - val_accuracy: 0.4000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 1.0361 - accuracy: 0.7778 - val_loss: 1.0565 - val_accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aad344cadd0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train_text, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm-IjaLfKPQt",
        "outputId": "c82c8e55-bdfe-4fc8-9236-436e7cc5a4e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step - loss: 0.9991 - accuracy: 0.8333\n",
            "Test Loss: 0.9991, Test Accuracy: 0.8333\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_text, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSm6dYB2KPTR",
        "outputId": "a248f2e9-66d2-4afd-dd22-02c872367f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happy with the purchase! :smiling_face_with_heart-eyes::thumbs_up:', 'disappointing experience. :pensive_face::crying_face:', \"it's okay.:thinking_face:\"]\n"
          ]
        }
      ],
      "source": [
        "# Predicting new data\n",
        "new_texts = [\"Happy with the purchase! 😍👍\",\"Disappointing experience. 😔😢\", \"It's okay.🤔\"]\n",
        "new_texts_preprocessed = [preprocess_and_analyze_sentiment(text)[0] for text in new_texts]\n",
        "print(new_texts_preprocessed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBUiU5tDKPVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39cb84f2-37dc-42a2-c2d5-c26ae16cb97c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[45, 3, 5, 29, 2, 1, 3, 15, 6, 8], [60, 61, 1, 1], [25, 63, 14, 1]]\n",
            "[[ 0  0  0  0  0  0  0  0  0  0 45  3  5 29  2  1  3 15  6  8]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60 61  1  1]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 25 63 14  1]]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize and pad sequences for new text\n",
        "X_new_text = tokenizer.texts_to_sequences(new_texts_preprocessed)\n",
        "print(X_new_text)\n",
        "X_new_text = pad_sequences(X_new_text, maxlen=max_len_text)\n",
        "print(X_new_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQYj_8VCMAZ1",
        "outputId": "12a17993-e829-40c2-9d31-76288d2859a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 583ms/step\n",
            "[[0.3595397  0.26513383 0.37532648]\n",
            " [0.3539489  0.2721948  0.3738563 ]\n",
            " [0.34676448 0.28229824 0.37093732]]\n"
          ]
        }
      ],
      "source": [
        " #Predict sentiments for new data\n",
        "predictions = model.predict(X_new_text)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLaCIYHEMAcQ",
        "outputId": "5511c3f7-ecf3-44d1-e645-488049d9c73e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Happy with the purchase! 😍👍, Predicted Probability (Positive, Negative, Neutral): [0.3595397  0.26513383 0.37532648]\n",
            "Text: Disappointing experience. 😔😢, Predicted Probability (Positive, Negative, Neutral): [0.3539489 0.2721948 0.3738563]\n",
            "Text: It's okay.🤔, Predicted Probability (Positive, Negative, Neutral): [0.34676448 0.28229824 0.37093732]\n"
          ]
        }
      ],
      "source": [
        "# Display predictions\n",
        "for i, text in enumerate(new_texts):\n",
        "    print(f\"Text: {text}, Predicted Probability (Positive, Negative, Neutral): {predictions[i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ORo8wm3MAeu",
        "outputId": "ff653374-7804-4cff-b7fc-dbe34590be63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2]\n"
          ]
        }
      ],
      "source": [
        "# Convert probabilities to binary predictions\n",
        "binary_predictions = np.argmax(predictions, axis=1)\n",
        "print(binary_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dq_ekNQMAha"
      },
      "outputs": [],
      "source": [
        "# Display binary predictions\n",
        "for i, text in enumerate(new_texts):\n",
        "    sentiment = 'Positive' if binary_predictions[i] == 0 else ('Negative' if binary_predictions[i] == 1 else 'Neutral')\n",
        "    print(f\"Text: {text}, Predicted Sentiment:\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}